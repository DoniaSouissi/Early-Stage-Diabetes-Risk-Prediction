{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2898a0",
   "metadata": {},
   "source": [
    "#  Data Preparation & Preprocessing\n",
    "## Early Stage Diabetes Risk Prediction\n",
    "\n",
    "###  Objective\n",
    "In this notebook, we will transform the raw data into a format suitable for machine learning models.\n",
    "Based on our EDA findings, we will implement the following pipeline:\n",
    "\n",
    "1.  **Data Splitting:** Divide data into Train, Validation, and Test sets (60/20/20).\n",
    "2.  **Numerical Scaling:** Apply `StandardScaler` to the `Age` column.\n",
    "3.  **Categorical Encoding:** Apply `OneHotEncoder` (binary mode) to all symptom columns.\n",
    "4.  **Target Encoding:** Convert `Positive`/`Negative` classes to `1`/`0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64cd5914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib  # To save our scalers/encoders for later use\n",
    "\n",
    "# Load the raw data\n",
    "df = pd.read_csv('../data/raw/diabetes_data_upload.csv')\n",
    "\n",
    "print(\"Data Loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f8962",
   "metadata": {},
   "source": [
    "## 1. Train-Validation-Test Split\n",
    "We split the data **before** any processing to prevent \"Data Leakage\" (information from the test set leaking into the training process).\n",
    "\n",
    "* **Train Set (60%):** Used to teach the model.\n",
    "* **Validation Set (20%):** Used to tune hyperparameters.\n",
    "* **Test Set (20%):** Used for the final unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17832e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:   (312, 16)\n",
      "Validation Set: (104, 16)\n",
      "Testing Set:    (104, 16)\n"
     ]
    }
   ],
   "source": [
    "# Separate Features (X) and Target (y)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# First Split: 80% Train+Val, 20% Test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second Split: Split the 80% into Train (75%) and Val (25%) -> Results in 60% Train, 20% Val overall\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training Set:   {X_train.shape}\")\n",
    "print(f\"Validation Set: {X_val.shape}\")\n",
    "print(f\"Testing Set:    {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dcfbf2",
   "metadata": {},
   "source": [
    "## 2. Defining the Preprocessing Pipeline\n",
    "We will use Scikit-Learn's `ColumnTransformer` to apply different logic to different columns simultaneously.\n",
    "\n",
    "* **Numerical (`Age`):** Requires `StandardScaler` (Mean=0, Std=1).\n",
    "* **Categorical (Symptoms):** Requires `OneHotEncoder`. We use `drop='first'` to turn binary columns (Male/Female) into a single column (0/1) to avoid redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f740ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline defined successfully.\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify Column Types\n",
    "numeric_features = ['Age']\n",
    "categorical_features = [col for col in X.columns if col != 'Age']\n",
    "\n",
    "# 2. Define Transformers\n",
    "# For Age: Scale it\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For Symptoms: Encode \"Yes\"/\"No\" to 1/0\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. Combine into a Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False # Keeps column names clean (e.g., \"Gender_Male\" instead of \"cat__Gender_Male\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Pipeline defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4859b4",
   "metadata": {},
   "source": [
    "## 3. Applying Transformations\n",
    "We **Fit** the preprocessor ONLY on the Training data, and then **Transform** the Validation and Test data. This ensures the model never \"sees\" the test statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af98cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of Processed Data (First 5 rows of Train):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Polyuria_Yes</th>\n",
       "      <th>Polydipsia_Yes</th>\n",
       "      <th>sudden weight loss_Yes</th>\n",
       "      <th>weakness_Yes</th>\n",
       "      <th>Polyphagia_Yes</th>\n",
       "      <th>Genital thrush_Yes</th>\n",
       "      <th>visual blurring_Yes</th>\n",
       "      <th>Itching_Yes</th>\n",
       "      <th>Irritability_Yes</th>\n",
       "      <th>delayed healing_Yes</th>\n",
       "      <th>partial paresis_Yes</th>\n",
       "      <th>muscle stiffness_Yes</th>\n",
       "      <th>Alopecia_Yes</th>\n",
       "      <th>Obesity_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.128102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.779358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.045169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.713437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.045169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender_Male  Polyuria_Yes  Polydipsia_Yes  \\\n",
       "0  1.128102          1.0           1.0             0.0   \n",
       "1 -0.779358          0.0           1.0             1.0   \n",
       "2  1.045169          1.0           0.0             0.0   \n",
       "3  0.713437          1.0           0.0             1.0   \n",
       "4  1.045169          1.0           1.0             1.0   \n",
       "\n",
       "   sudden weight loss_Yes  weakness_Yes  Polyphagia_Yes  Genital thrush_Yes  \\\n",
       "0                     0.0           1.0             0.0                 1.0   \n",
       "1                     1.0           1.0             1.0                 0.0   \n",
       "2                     0.0           1.0             0.0                 1.0   \n",
       "3                     0.0           1.0             0.0                 1.0   \n",
       "4                     1.0           1.0             1.0                 1.0   \n",
       "\n",
       "   visual blurring_Yes  Itching_Yes  Irritability_Yes  delayed healing_Yes  \\\n",
       "0                  1.0          1.0               1.0                  0.0   \n",
       "1                  0.0          1.0               1.0                  1.0   \n",
       "2                  0.0          1.0               0.0                  1.0   \n",
       "3                  1.0          0.0               1.0                  1.0   \n",
       "4                  1.0          1.0               0.0                  0.0   \n",
       "\n",
       "   partial paresis_Yes  muscle stiffness_Yes  Alopecia_Yes  Obesity_Yes  \n",
       "0                  1.0                   1.0           1.0          1.0  \n",
       "1                  1.0                   0.0           0.0          0.0  \n",
       "2                  0.0                   0.0           1.0          0.0  \n",
       "3                  1.0                   1.0           1.0          0.0  \n",
       "4                  0.0                   0.0           1.0          1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit on Train, Transform Train\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform Val and Test (using the rules learned from Train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# --- Rebuild DataFrames ---\n",
    "# The output of transformers is a numpy array. We put it back into a DataFrame for readability.\n",
    "\n",
    "# Get new column names\n",
    "new_columns = numeric_features + list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features))\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=new_columns)\n",
    "X_val_df = pd.DataFrame(X_val_processed, columns=new_columns)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=new_columns)\n",
    "\n",
    "print(\"Preview of Processed Data (First 5 rows of Train):\")\n",
    "display(X_train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c60dd",
   "metadata": {},
   "source": [
    "### Interpretation of Changes:\n",
    "* **Age:** Now appears as a decimal (e.g., `0.5`, `-1.2`) because it is standardized.\n",
    "* **Gender:** Has become `Gender_Male` (1 if Male, 0 if Female).\n",
    "* **Polyuria:** Has become `Polyuria_Yes` (1 if Yes, 0 if No)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979e8d",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Note: Where did the 'Female' column go?\n",
    "\n",
    "You noticed that we have a `Gender_Male` column but no `Gender_Female` column. This is intentional and caused by the parameter `drop='first'` in our `OneHotEncoder`.\n",
    "\n",
    "* **How it works:** We only need **one** column to represent two binary options.\n",
    "    * If `Gender_Male` is **1**, the patient is **Male**.\n",
    "    * If `Gender_Male` is **0**, the patient is **Female**.\n",
    "* **Why we do this:** Adding a second column (like `Gender_Female`) would create duplicate information (redundancy). Removing it prevents a mathematical problem called the **\"Dummy Variable Trap\"** (Multicollinearity), making our model cleaner and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4de6b",
   "metadata": {},
   "source": [
    "## 4. Target Encoding\n",
    "The target column (`class`) contains \"Positive\" and \"Negative\". We must convert this to `1` and `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e8b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Mapping: {'Negative': np.int64(0), 'Positive': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "target_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on Train, Transform everything\n",
    "y_train_encoded = target_encoder.fit_transform(y_train)\n",
    "y_val_encoded = target_encoder.transform(y_val)\n",
    "y_test_encoded = target_encoder.transform(y_test)\n",
    "\n",
    "# Check the mapping\n",
    "print(f\"Class Mapping: {dict(zip(target_encoder.classes_, target_encoder.transform(target_encoder.classes_)))}\")\n",
    "# Expect: {'Negative': 0, 'Positive': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba325d8",
   "metadata": {},
   "source": [
    "## 5. Saving Processed Data\n",
    "We save the processed arrays and the preprocessor object. Saving the `preprocessor` is crucial because we will need it later to process new real-world data in our web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d6e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All files saved to 'data/processed/' and 'models/'\n"
     ]
    }
   ],
   "source": [
    "# Save DataFrames\n",
    "X_train_df.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_val_df.to_csv('../data/processed/X_val.csv', index=False)\n",
    "X_test_df.to_csv('../data/processed/X_test.csv', index=False)\n",
    "\n",
    "# Save Targets (as DataFrames for consistency)\n",
    "pd.DataFrame(y_train_encoded, columns=['class']).to_csv('../data/processed/y_train.csv', index=False)\n",
    "pd.DataFrame(y_val_encoded, columns=['class']).to_csv('../data/processed/y_val.csv', index=False)\n",
    "pd.DataFrame(y_test_encoded, columns=['class']).to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "# Save the Preprocessor and Target Encoder (For the App/Inference later)\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True) # Ensure folder exists\n",
    "\n",
    "joblib.dump(preprocessor, '../models/preprocessor.joblib')\n",
    "joblib.dump(target_encoder, '../models/target_encoder.joblib')\n",
    "\n",
    "print(\"âœ… All files saved to 'data/processed/' and 'models/'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
